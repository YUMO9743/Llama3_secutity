# Llama3: Instruction Fine-Tuning Open-Source LLM for Network Security Analysis

## Directory Structure

- **training_data**: The main training data for Llama3. There are two separate files for Network analysis and Security analysis. Each combined all the instructions used in training in the area, totaling 15,111 instruction sets for Network Analysis and 10171 for Security Analysis. 

- **generated_results**: JSON files containing specific results that were generated by the trained model.

- **finetuning**: Python scripts designed for instruction fine-tuning of LLaMA3 8B.

- **validating**: Three JSON files containing the testing data for different functionalities.

## Getting Started
### Install
Clone this repository and navigate to the folder.
```bash
git clone github.com/DNLab2024/Mobile-LLaMA.git
cd Mobile-LLaMA
```
Install Package (python>=3.9)
```bash
pip install -r requirements.txt
```
Run fine-tuning
```bash
python3 llama3_finetune.py     --output_dir "../llama3_security"     --batch_size 2     --gradient_accumulation_steps 4     --optim "paged_adamw_32bit"    --logging_steps 200    --learning_rate 0.0001    --max_grad_norm 0.3     --max_steps 8000    --warmup_ratio 0.05     --lora_alpha 16    --lora_dropout 0.1     --lora_r 64    --num_train_epochs 2.0
```
Run testing example
```bash
python test_security.py --test_file ./validating/validate_logs.json
```

## Finetuning example
```bash
python ./finetuning/llama3_finetune.py     --output_dir "../llama3_security"     --batch_size 2     --gradient_accumulation_steps 4     --optim "paged_adamw_32bit"    --logging_steps 200    --learning_rate 0.0001    --max_grad_norm 0.3     --max_steps 8000    --warmup_ratio 0.05     --lora_alpha 16    --lora_dropout 0.1     --lora_r 64    --num_train_epochs 2.0
```

# Testing example
```bash
python ./test_security.py --test_file ./validating/validate_logs.json
```
